#!/usr/bin/env python
# coding: utf-8

"""
generate_synthetic_images.py

Loads a base SD model + your LoRA layers + your custom token embeddings,
then generates synthetic images via text-to-image. For example, you can produce
50 new "dermatofibroma" images.

Usage (example):
---------------
python generate_synthetic_images.py \
  --pretrained_model="runwayml/stable-diffusion-v1-5" \
  --lora_weights="models/dermatofibroma_lora/pytorch_lora_weights.safetensors" \
  --token_embeds="models/dermatofibroma_lora/learned_embeds.safetensors" \
  --custom_token="<LESION>" \
  --prompt="A close-up photo of <LESION> lesion on the skin." \
  --num_images=50 \
  --output_dir="synthetic_derma"

"""

import argparse
import os
import torch
from diffusers import StableDiffusionPipeline
from diffusers.loaders import StableDiffusionLoraLoaderMixin
from safetensors import torch as st_torch
from PIL import Image


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--pretrained_model",
        type=str,
        required=True,
        help="Base stable diffusion model on Hugging Face, e.g. runwayml/stable-diffusion-v1-5",
    )
    parser.add_argument(
        "--lora_weights",
        type=str,
        required=True,
        help="Path to LoRA weights (pytorch_lora_weights.safetensors) generated by train_lora.py",
    )
    parser.add_argument(
        "--token_embeds",
        type=str,
        required=True,
        help="Path to learned_embeds.safetensors for your custom token.",
    )
    parser.add_argument(
        "--custom_token",
        type=str,
        default="<LESION>",
        help="Your token placeholder used in training.",
    )
    parser.add_argument(
        "--prompt",
        type=str,
        default="A photo of <LESION> lesion on the skin, ultra-detailed",
        help="Prompt that references your custom token. E.g: 'A close-up of <LESION> lesion...'",
    )
    parser.add_argument("--num_images", type=int, default=10)
    parser.add_argument("--guidance_scale", type=float, default=7.5)
    parser.add_argument("--num_inference_steps", type=int, default=50)
    parser.add_argument("--seed", type=int, default=1234)
    parser.add_argument("--output_dir", type=str, default="outputs_lora_gen")
    return parser.parse_args()


def main():
    args = parse_args()
    os.makedirs(args.output_dir, exist_ok=True)

    # 1) Load base model
    pipe = StableDiffusionPipeline.from_pretrained(
        args.pretrained_model,
        torch_dtype=torch.float16,  # or "auto" / torch.float16
    ).to("cuda")

    # 2) Load LoRA
    # The diffusers library includes a "load_lora_weights" method
    # stable diffusion text encoder + unet
    pipe.load_lora_weights(args.lora_weights)

    # 3) Load custom token embeddings
    loaded_dict = st_torch.load_file(args.token_embeds)
    # This dict is {token_str: embedding_tensor}
    # We'll add the token to the pipe.tokenizer, and patch the text_encoder
    for token_str, embed in loaded_dict.items():
        # add the token if not already present
        if token_str not in pipe.tokenizer.get_vocab():
            pipe.tokenizer.add_tokens(token_str)
            # resize token embeddings
            pipe.text_encoder.resize_token_embeddings(len(pipe.tokenizer))

        # now find the ID for the newly added token
        token_id = pipe.tokenizer.convert_tokens_to_ids(token_str)
        # assign the learned embedding
        with torch.no_grad():
            pipe.text_encoder.get_input_embeddings().weight[token_id] = embed.to(
                pipe.text_encoder.dtype
            ).cuda()

    # 4) Generate images
    generator = torch.Generator(device="cuda").manual_seed(args.seed)

    prompt = args.prompt
    for i in range(args.num_images):
        image = pipe(
            prompt,
            num_inference_steps=args.num_inference_steps,
            guidance_scale=args.guidance_scale,
            generator=generator,
        ).images[0]

        outpath = os.path.join(args.output_dir, f"generated_{i:03d}.png")
        image.save(outpath)
        print(f"Saved {outpath}")


if __name__ == "__main__":
    main()
